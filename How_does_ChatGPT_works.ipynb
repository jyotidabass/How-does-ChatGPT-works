{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPL9c9i/vqX88+vWO4tDlgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/How-does-ChatGPT-works/blob/main/How_does_ChatGPT_works.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Text Preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and special characters\n",
        "    text = ''.join(e for e in text if e.isalnum() or e.isspace())\n",
        "    # Tokenize the text\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Step 2: Embedding\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, indices):\n",
        "        # Get the embeddings\n",
        "        embeddings = self.embedding(indices)\n",
        "        return embeddings\n",
        "\n",
        "# Step 3: Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        # Forward pass\n",
        "        outputs = torch.relu(self.fc1(embeddings))\n",
        "        outputs = self.fc2(outputs)\n",
        "        return outputs\n",
        "\n",
        "# Step 4: Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, outputs):\n",
        "        # Forward pass\n",
        "        outputs = torch.relu(self.fc1(outputs))\n",
        "        outputs = self.fc2(outputs)\n",
        "        return outputs\n",
        "\n",
        "# Step 5: Training\n",
        "def train(model, inputs, targets, epochs):\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph=True)  # retain_graph=True added here\n",
        "        optimizer.step()\n",
        "        # Print the loss\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Define the vocabulary\n",
        "vocab = ['hello', 'world', 'how', 'are', 'you']\n",
        "\n",
        "# Define the model\n",
        "embedding = Embedding(len(vocab), 10)\n",
        "encoder = Encoder(10, 20, 10)\n",
        "decoder = Decoder(10, 20, len(vocab))\n",
        "\n",
        "# Define the inputs and targets\n",
        "input_text = preprocess_text('hello world')\n",
        "input_indices = torch.tensor([vocab.index(token) for token in input_text])\n",
        "input_embeddings = embedding(input_indices)\n",
        "\n",
        "# Change targets to have the same batch size as input_embeddings\n",
        "# We can assume the target for 'hello' is 'how' and for 'world' is 'are'\n",
        "targets = torch.tensor([vocab.index('how'), vocab.index('are')])\n",
        "\n",
        "# Train the model\n",
        "train(decoder, input_embeddings, targets, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2jDoheFzuN",
        "outputId": "6dee377a-3db8-427e-e3f4-f99c741068cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.356130599975586\n",
            "Epoch 2, Loss: 1.3400578498840332\n",
            "Epoch 3, Loss: 1.3240325450897217\n",
            "Epoch 4, Loss: 1.3080558776855469\n",
            "Epoch 5, Loss: 1.2921299934387207\n",
            "Epoch 6, Loss: 1.2762569189071655\n",
            "Epoch 7, Loss: 1.2604382038116455\n",
            "Epoch 8, Loss: 1.2446751594543457\n",
            "Epoch 9, Loss: 1.2289683818817139\n",
            "Epoch 10, Loss: 1.2133179903030396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a test input\n",
        "test_input_text = preprocess_text('hello world')\n",
        "test_input_indices = torch.tensor([vocab.index(token) for token in test_input_text])\n",
        "test_input_embeddings = embedding(test_input_indices)\n",
        "\n",
        "# Evaluate the model on the test input\n",
        "test_outputs = decoder(test_input_embeddings)\n",
        "print(test_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIwO82PMGfFe",
        "outputId": "41534988-1381-4c82-9347-3f8094b9b8fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0101, -0.2192,  0.5440,  0.0839, -0.1989],\n",
            "        [ 0.0877, -0.4793,  0.0412,  0.3301, -0.3754]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}